{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_tut.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9ljW5guLaW33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf;\n",
        "\n",
        "n_classes = 5\n",
        "batch_size = 5\n",
        "\n",
        "x = tf.placeholder('float', name = \"MyInput\")\n",
        "#x = tf.placeholder('float')\n",
        "y = tf.placeholder('float')\n",
        "\n",
        "def conv2d(x, W):\n",
        "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "def maxpool2d(x):\n",
        "\treturn tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "\n",
        "def convolutional_neural_network(x):\n",
        "\tweights = {'W_conv1': tf.Variable(tf.random_normal([5,5,3,32])),\n",
        "\t\t\t\t'W_conv2': tf.Variable(tf.random_normal([5,5,32,64])),\n",
        "\t\t\t\t'W_fc': tf.Variable(tf.random_normal([5*10*64, 1024])),\n",
        "\t\t\t\t'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
        "\n",
        "\tbiases = {'b_conv1': tf.Variable(tf.random_normal([32])),\n",
        "\t\t\t\t'b_conv2': tf.Variable(tf.random_normal([64])),\n",
        "\t\t\t\t'b_fc': tf.Variable(tf.random_normal([1024])),\n",
        "\t\t\t\t'out': tf.Variable(tf.random_normal([n_classes]))}\n",
        "\n",
        "\tx= tf.reshape(x, shape=[-1, 20, 40,3])\n",
        "\tconv1 = conv2d(x, weights['W_conv1'])\n",
        "\tconv1 = maxpool2d(conv1)\n",
        "\n",
        "\tconv2= conv2d(conv1, weights['W_conv2'])\n",
        "\tconv2 = maxpool2d(conv2)\n",
        "\n",
        "\tfc= tf.reshape(conv2, [-1,5*10*64])\n",
        "\tfc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
        "\n",
        "\t#fc = tf.nn.dropout(fc, keep_rate)\n",
        "\n",
        "\toutput = tf.matmul(fc, weights['out'])+biases['out']\n",
        "\t#output = tf.identity(output, name=\"MyOutput\")\n",
        "\treturn output\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIGhF2BvUeFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1Za518cSPz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.python.tools import optimize_for_inference_lib, freeze_graph\n",
        "#mkdir New_model\n",
        "#!mv saved_model.pb New_model/saved_model.pb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eToQn7mSYCe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generate_from_TFRecord():\n",
        "\tdef __init__(self, tfrecord_file):\n",
        "\t\tself.tfrecord = tfrecord_file\n",
        "\n",
        "\tdef extract_image_data(self,batch_size, shuffle):\n",
        "\t\tdef _extract_fn(tfrecord):\n",
        "\t\t\tfeatures={\n",
        "\t\t\t\t'image/height': tf.FixedLenFeature([], tf.int64),\n",
        "\t\t\t\t'image/width': tf.FixedLenFeature([], tf.int64),\n",
        "\t\t\t\t'image/image_raw': tf.FixedLenFeature([], tf.string),\n",
        "\t\t\t\t'image/class/label': tf.FixedLenFeature([], tf.int64),\n",
        "\t\t\t\t'image/class/text': tf.FixedLenFeature([], tf.string)}\n",
        "\n",
        "\t\t\tsample = tf.parse_single_example(tfrecord, features)\n",
        "\n",
        "\t\t\t#image = tf.decode_raw(sample['image/image_raw'],tf.uint8)\n",
        "\t\t\timage = tf.image.decode_jpeg(sample['image/image_raw'])\n",
        "\t\t\theight = tf.cast(sample['image/height'], tf.int32)\n",
        "\t\t\twidth = tf.cast(sample['image/width'], tf.int32)\n",
        "\t\t\timage = tf.reshape(image,[1,height*width*3])\n",
        "\t\t\t#image = tf.reshape(image, [height, width, 3])\n",
        "\t\t\tlabel = tf.cast(sample['image/class/label'], tf.int32)\n",
        "\t\t\tlabel_txt = tf.cast(sample['image/class/text'], tf.string)\n",
        "\t\t\t\n",
        "\t\t\treturn [image, label_txt, label, height, width]\n",
        "\n",
        "\t\ttfrecord_file = self.tfrecord\n",
        "\t\tdataset = tf.data.TFRecordDataset([tfrecord_file])\n",
        "\t\tdataset = dataset.map(_extract_fn)\n",
        "\n",
        "\t\tif batch_size != None:\n",
        "\t\t\tprint(\"Preparing batches.....\")\n",
        "\t\t\tdataset = dataset.batch(batch_size)\n",
        "\t\t#dataset = dataset.repeat(10)\n",
        "\t\tif shuffle == True:\n",
        "\t\t\tprint(\"Shuffling.....\")\n",
        "\t\t\tdataset= dataset.shuffle(buffer_size = len(tfrecord_file))\n",
        "\t\treturn dataset\n",
        "\n",
        "\tdef generate_data(self, batch_size = None, shuffle = False):\n",
        "\t\tprint(\"TFRecord file used: \", self.tfrecord)\n",
        "\t\tdataset = self.extract_image_data(batch_size, shuffle)\n",
        "\t\titerator = dataset.make_one_shot_iterator()\n",
        "\t\tnext_batch = iterator.get_next()\n",
        "\t\treturn next_batch\n",
        "\t\t\n",
        "\n",
        "\tdef get_num_examples(self):\n",
        "\t\tcnt=0\n",
        "\t\timge, text, lab, ht, wdth = self.generate_data()\n",
        "\t\twith tf.Session() as sess:\n",
        "\t\t\tsess.run(tf.initializers.global_variables())\n",
        "\t\t\ttry:\n",
        "\t\t\t\twhile(1):\n",
        "\t\t\t\t\timg_dat, txt, labl, hgth, wth = sess.run([imge, text, lab, ht, wdth])\n",
        "\t\t\t\t\tcnt+=1\n",
        "\t\t\texcept:\n",
        "\t\t\t\tpass\n",
        "\t\treturn cnt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKHwQ54vVy4j",
        "colab_type": "code",
        "outputId": "d194d2f5-e5f8-4885-cb49-d2c9f54b8bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "dat = Generate_from_TFRecord('drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord')\n",
        "print('NUMS:: ', dat.get_num_examples())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "NUMS::  851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AHexN2GRS-AG",
        "colab_type": "code",
        "outputId": "2ec1db35-07bd-48ee-aee9-ab5b68d6dc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "cell_type": "code",
      "source": [
        "def train_CNN_for_pathFollowing(tfrecordFile,valida_tfrecordFile, batch_size):\n",
        "  train_data = Generate_from_TFRecord(tfrecordFile)\n",
        "  train_nums = train_data.get_num_examples()\n",
        "  \n",
        "  #train_image, _, train_label,_, _ = train_data.generate_data(batch_size= batch_size)\n",
        "  #valid_data = Generate_from_TFRecord(valida_tfrecordFile)\n",
        "  #valid_nums = valid_data.get_num_examples()\n",
        "  #valid_image, _, valid_label,_, _ = valid_data.generate_data()\n",
        "  \n",
        "  print (\"Using \", tfrecordFile, \"for training and \", valida_tfrecordFile,\"for validation\")\n",
        "  \n",
        "  prediction = convolutional_neural_network(x)\n",
        "  prediction = tf.identity(prediction, name=\"myOutput\")\n",
        "\t#y_clipped = tf.clip_by_value(prediction, 1e-10, 0.9999999)\n",
        "\t#cost = tf.reduce_mean(tf.reduce_sum(y*tf.log(y_clipped) + (1-y) * tf.log(1-y_clipped), axis = 1))\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\t#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)\n",
        "\t# cycles for feed forward and backprop\n",
        "  hm_epoch = 5\n",
        "  save_path = \"/content/model_final.ckpt\"\n",
        "  saver = tf.train.Saver()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    total_batch = int(train_nums/batch_size)\n",
        "    valid_data = Generate_from_TFRecord(valida_tfrecordFile)\n",
        "    valid_nums = valid_data.get_num_examples()\n",
        "    valid_image, _, valid_label,_, _ = valid_data.generate_data()\n",
        "    \n",
        "    for epoch in range(hm_epoch):\n",
        "      epoch_loss = 0\n",
        "      train_data = Generate_from_TFRecord(tfrecordFile)\n",
        "      train_nums = train_data.get_num_examples()\n",
        "      train_image, _, train_label,_, _ = train_data.generate_data(batch_size= batch_size)\n",
        "      \n",
        "      for _ in range(total_batch):\n",
        "        epoch_x, epoch_y = sess.run([train_image, train_label])\n",
        "        #print(\"Shape:>>>>\", epoch_x.shape)\n",
        "        epoch_y = sess.run(tf.one_hot(epoch_y, depth=5))\n",
        "        _, c = sess.run([optimizer , cost], feed_dict = {x: epoch_x , y:epoch_y})\n",
        "        epoch_loss += c\n",
        "      print ('Epoch ', epoch+1, 'completed out of ', hm_epoch, 'Loss: ', epoch_loss)\n",
        "    \n",
        "    correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "    inputs={\"myInput\": x}\n",
        "    outputs={\"myOutput\": prediction}\n",
        "    valid_x=np.array([])\n",
        "    valid_y=np.array([])\n",
        "    tf.saved_model.simple_save(sess, '/content/model_more/',inputs, outputs)\n",
        "    print(\"saving using Saver::.......................................\")\n",
        "    saver.save(sess, save_path)\n",
        "    cnc=0\n",
        "    try:\n",
        "      while(1):\n",
        "        cnc+=1\n",
        "        Vx, Vy = sess.run([valid_image, valid_label])\n",
        "        Vy = sess.run(tf.one_hot(Vy, depth=5))\n",
        "        Vy = sess.run(tf.reshape(Vy,[1,len(Vy)]))\n",
        "        #Vy = Vy.reshape((1,len(Vy)))\n",
        "        #print(\">>\",Vx.shape, Vy.shape,valid_x.size==0)\n",
        "        if valid_x.size==0:\n",
        "          #valid_x = np.append(valid_x,Vx)\n",
        "          valid_x = Vx[:]\n",
        "          #print(\"<<<>>>\", valid_x)\n",
        "          #valid_x = sess.run(tf.reshape(valid_x,[1,len(valid_x)]))\n",
        "          valid_y = Vy[:]\n",
        "          #valid_y = sess.run(tf.reshape(valid_y,[1,len(valid_y)]))\n",
        "        else:\n",
        "          #print(\"Stacking....\")\n",
        "          valid_x = np.append(valid_x,Vx,axis=0)\n",
        "          valid_y = np.append(valid_y,Vy, axis=0)\n",
        "        \n",
        "    except:\n",
        "      print (\"Passing....>.\", cnc)\n",
        "      pass\n",
        "    print(valid_x.shape)\n",
        "    print(valid_y.shape)\n",
        "    print ('Accuracy:: ', accuracy.eval({x:valid_x , y:valid_y}) )\n",
        "    #saver.save(sess, save_path)\n",
        "  \n",
        "validation_tf = 'drive/My Drive/Dataset/path_foll_compr_reshaped_more_validation.tfrecord' \n",
        "training_tf = 'drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord'\n",
        "train_CNN_for_pathFollowing(training_tf, validation_tf, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "Using  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord for training and  drive/My Drive/Dataset/path_foll_compr_reshaped_more_validation.tfrecord for validation\n",
            "WARNING:tensorflow:From <ipython-input-7-faed33583fbc>:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_validation.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_validation.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "Preparing batches.....\n",
            "Epoch  1 completed out of  5 Loss:  559613744.40625\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "Preparing batches.....\n",
            "Epoch  2 completed out of  5 Loss:  151468515.3203125\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "Preparing batches.....\n",
            "Epoch  3 completed out of  5 Loss:  75626283.8828125\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "Preparing batches.....\n",
            "Epoch  4 completed out of  5 Loss:  57368876.83154297\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_train.tfrecord\n",
            "Preparing batches.....\n",
            "Epoch  5 completed out of  5 Loss:  54336679.25390625\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Pass your op to the equivalent parameter main_op instead.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/model_more/saved_model.pb\n",
            "saving using Saver::.......................................\n",
            "Passing....>. 47\n",
            "(46, 2400)\n",
            "(46, 5)\n",
            "Accuracy::  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OFS_pLs5tlAo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Restoring from saved model.**"
      ]
    },
    {
      "metadata": {
        "id": "BGCcne0DqBAk",
        "colab_type": "code",
        "outputId": "29c1ac69-6921-4278-bd73-2f28d42abaa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "validation_tf_vis = 'drive/My Drive/Dataset/path_foll_compr_reshaped_more_validation.tfrecord'\n",
        "valid_data = Generate_from_TFRecord(validation_tf_vis)\n",
        "valid_image, _, valid_label,_, _ = valid_data.generate_data()\n",
        "cn = 0\n",
        "test_data = np.array([])\n",
        "test_label = np.array([])\n",
        "with tf.Session() as sess:\n",
        "  try:\n",
        "      while(1):\n",
        "        cn+=1\n",
        "        Vx, Vy = sess.run([valid_image, valid_label])\n",
        "        Vy = sess.run(tf.one_hot(Vy, depth=5))\n",
        "        Vy = sess.run(tf.reshape(Vy,[1,len(Vy)]))\n",
        "        if test_data.size==0:\n",
        "          test_data = Vx[:]\n",
        "          test_label = Vy[:]\n",
        "        else:\n",
        "          test_data = np.append(test_data,Vx,axis=0)\n",
        "          test_label = np.append(test_label,Vy, axis=0)\n",
        "  except:\n",
        "    print (\"Passing..\", cn)\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFRecord file used:  drive/My Drive/Dataset/path_foll_compr_reshaped_more_validation.tfrecord\n",
            "Passing.. 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Z9V4mHrv679",
        "colab_type": "code",
        "outputId": "7867d68f-024f-4328-fb40-0f1f725651dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "tf.reset_default_graph()\n",
        "imported_meta = tf.train.import_meta_graph(\"model_final.ckpt.meta\")\n",
        "#x = tf.placeholder('float')\n",
        "#y = tf.placeholder('float')\n",
        "#prediction = convolutional_neural_network(x) \n",
        "with tf.Session() as sess:\n",
        "  imported_meta.restore(sess,tf.get.latest_checkpoint('./'))\n",
        "  #print(sess.run('valix_x')) \n",
        "  corr = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "  accu = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "  print ('Accuracy:: ', accu.eval({x:data.test , y:data_label, session=sess}) )\n",
        "  #prediction=tf.argmax(y,1)\n",
        "  #print (prediction.eval(feed_dict={x: test_data, },session=sess))\n",
        "\n",
        "'''\n",
        "'''\n",
        "saver = tf.train.import_meta_graph(\"model_final.ckpt.meta\")\n",
        "graph = tf.get_default_graph()\n",
        "\n",
        "x = graph.get_tensor_by_name('output/BiasAdd:0')\n",
        "print (x.type)\n",
        "'''\n",
        "#tf.saved_model.loader.load(sess, [tag_constants.SERVING],'/content/New_model/model/' )\n",
        "gr=tf.Graph()\n",
        "ip = tf.placeholder('float')\n",
        "prediction = tf.placeholder('float')\n",
        "save_path = '/content/model.ckpt'\n",
        "#with graph.as_default():\n",
        "with tf.Session() as sess:\n",
        "  tf.saved_model.loader.load(sess, [tag_constants.SERVING],'/content/model/' )\n",
        "  gr =  tf.get_default_graph()\n",
        "  ip = gr.get_tensor_by_name('MyInput:0') \n",
        "  print(\"Input shape: \",ip.shape)\n",
        "  prediction = gr.get_tensor_by_name('myOutput:0')\n",
        "  print(\"OP shape: \",prediction.shape)\n",
        "  #print(sess.run(graph.is_feedable('myOutput:0')))\n",
        "  print (sess.run(prediction, feed_dict={ip:test_data[6]}))\n",
        "  #print (sess.run('myOutput:0', feed_dict={'MyInput:0':test_data}))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model/variables/variables\n",
            "Input shape:  <unknown>\n",
            "OP shape:  (?, 5)\n",
            "[[1.2606353e+07 1.6259604e+06 1.2832307e+08 8.8431940e+06 3.3300906e+08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UM2N2jXW49tb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir ckpt\n",
        "!mv checkpoint ckpt/\n",
        "!mv model_f* ckpt/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A-vLYCVAejhM",
        "colab_type": "code",
        "outputId": "400ebf39-1bd2-46b2-cb03-e893f445a9f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!tar -czvf model.tar.gz model_more/\n",
        "#!mv '/content/ckpt/model_more' '/content/'\n",
        "#from google.colab import files\n",
        "#files.download('model.tar.gz')\n",
        "#!cp model.tar.gz 'drive/My Drive/Dataset/'\n",
        "!tar -czvf ckpt.tar.gz ckpt/\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_more/\n",
            "model_more/variables/\n",
            "model_more/variables/variables.data-00000-of-00001\n",
            "model_more/variables/variables.index\n",
            "model_more/saved_model.pb\n",
            "ckpt/\n",
            "ckpt/checkpoint\n",
            "ckpt/model_final.ckpt.meta\n",
            "ckpt/model_final.ckpt.index\n",
            "ckpt/model_final.ckpt.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q1b6hEUrVUuZ",
        "colab_type": "code",
        "outputId": "a9b2df50-ea52-47cf-9765-54e46ce00260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict = tf.contrib.predictor.from_saved_model('/content/model/')\n",
        "#x = tf.placeholder('float')\n",
        "#print (predict({\"myInput\":test_data[6]}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model/variables/variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z8yRuIASjzjM",
        "colab_type": "code",
        "outputId": "54af97ba-af42-4e4c-a7de-efd55ce450b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "op = predict({\"myInput\":test_data[35]})\n",
        "print (np.argmax(op['myOutput']))\n",
        "#print(predict({\"myInput\":test_data[6]}))\n",
        "#with tf.Session() as sess:\n",
        "#  print (sess.run(tf.argmax(predict({\"myInput\":test_data[6]}),1) ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XHG_oQTrp2aW",
        "colab_type": "code",
        "outputId": "37287abf-7707-4398-c433-989d6f21ad79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "#print (test_data[0].shape)\n",
        "\n",
        "imageToUse = test_data[32]\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(imageToUse,[20,40,3]), interpolation=\"nearest\", cmap=\"gray\", )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADGCAYAAAApIcCaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9b91dfeef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BOShmiLBTzap",
        "colab_type": "code",
        "outputId": "97512059-279b-4be0-b788-65d22d06a7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "file_metadata = {\n",
        "  'name': 'Sample file',\n",
        "  'mimeType': 'text/plain'\n",
        "}\n",
        "media = MediaFileUpload('/content/ckpt.tar.gz', \n",
        "                        mimetype='application/tar+gzip',\n",
        "                        resumable=True)\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1vNUd_vaWvllTs25NxQVYSLfYClxbuJxP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M5D_HnNASqxP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Freeze a graph\n"
      ]
    },
    {
      "metadata": {
        "id": "0zUWrUXCGdbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!mv /content/ckpt/freeze_mod.py /content/\n",
        "!cp -r drive/My\\ Drive/Dataset/ckpt/* /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJZEz_5kUgrm",
        "colab_type": "code",
        "outputId": "7e808eda-3844-4f82-e751-fd93826cc0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 freeze_mod.py --model_dir='/content/' --output_node_names=myOutput"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-20 04:40:53.934081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-20 04:40:53.934555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.79GiB\n",
            "2018-11-20 04:40:53.934604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-20 04:40:54.370690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-20 04:40:54.370765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-20 04:40:54.370792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-20 04:40:54.371110: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-11-20 04:40:54.371174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10453 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "27 ops in the final graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hc543rF2GMDi",
        "colab_type": "code",
        "outputId": "9031e35d-c6b6-4ea2-833e-3419c9ad36ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/ckpt/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint',\n",
              " 'model_final.ckpt.meta',\n",
              " 'model_final.ckpt.index',\n",
              " 'model_final.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "jUtydV4XcseP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Load Frozen Graph"
      ]
    },
    {
      "metadata": {
        "id": "0_TW4EPecKqJ",
        "colab_type": "code",
        "outputId": "d63f029a-2371-4860-c184-df13d025016b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def load_graph(frozen_graph_filename):\n",
        "    # We load the protobuf file from the disk and parse it to retrieve the \n",
        "    # unserialized graph_def\n",
        "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
        "        graph_def = tf.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "\n",
        "    # Then, we import the graph_def into a new Graph and returns it \n",
        "    with tf.Graph().as_default() as graph:\n",
        "        # The name var will prefix every op/nodes in your graph\n",
        "        # Since we load everything in a new graph, this is not needed\n",
        "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
        "    return graph\n",
        "\n",
        "\n",
        "gr = load_graph('frozen_model.pb')\n",
        "#op = predict({\"myInput\":test_data[35]})\n",
        "#print (np.argmax(op['myOutput']))\n",
        "print (gr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.framework.ops.Graph object at 0x7f9b89e5bdd8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "krmemj2hd0Ky",
        "colab_type": "code",
        "outputId": "4ab21bff-ec61-41a8-b373-66ee221026cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "##### Get list of operations and variables#######\n",
        "for op in gr.get_operations():\n",
        "  print(op.name)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prefix/MyInput\n",
            "prefix/Variable\n",
            "prefix/Variable/read\n",
            "prefix/Variable_1\n",
            "prefix/Variable_1/read\n",
            "prefix/Variable_2\n",
            "prefix/Variable_2/read\n",
            "prefix/Variable_3\n",
            "prefix/Variable_3/read\n",
            "prefix/Variable_6\n",
            "prefix/Variable_6/read\n",
            "prefix/Variable_7\n",
            "prefix/Variable_7/read\n",
            "prefix/Reshape/shape\n",
            "prefix/Reshape\n",
            "prefix/Conv2D\n",
            "prefix/MaxPool\n",
            "prefix/Conv2D_1\n",
            "prefix/MaxPool_1\n",
            "prefix/Reshape_1/shape\n",
            "prefix/Reshape_1\n",
            "prefix/MatMul\n",
            "prefix/add\n",
            "prefix/Relu\n",
            "prefix/MatMul_1\n",
            "prefix/add_1\n",
            "prefix/myOutput\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZanbLeWWpP2P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ip = gr.get_tensor_by_name('prefix/MyInput:0')\n",
        "prediction = gr.get_tensor_by_name('prefix/myOutput:0')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozLRXTVHMo11",
        "colab_type": "code",
        "outputId": "910f7938-200f-40c2-ce98-a9f66a76554e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session(graph=gr) as sess:\n",
        "  op = sess.run(prediction, feed_dict={ip:test_data[32]})\n",
        "  print (np.argmax(op))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BbRcqBWcN-5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Optimizing For Inference"
      ]
    },
    {
      "metadata": {
        "id": "s96Flw01QzdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python -m tensorflow.python.tools.optimize_for_inference --input=frozen_model.pb --output=optimized_graph.pb --input_names=\"MyInput\" --output_names=\"myOutput\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_g0bAHyHSxhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.gfile.GFile('optimized_graph.pb', 'rb') as f:\n",
        "   graph_def_optimized = tf.GraphDef()\n",
        "   graph_def_optimized.ParseFromString(f.read())\n",
        "\n",
        "G = tf.Graph()\n",
        "\n",
        "with tf.Session(graph=G) as sess:\n",
        "    y, = tf.import_graph_def(graph_def_optimized, return_elements=['myOutput:0'])\n",
        "    print('Operations in Optimized Graph:')\n",
        "    print([op.name for op in G.get_operations()])\n",
        "    x = G.get_tensor_by_name('import/MyInput:0')\n",
        "    prediction = G.get_tensor_by_name('import/myOutput:0')\n",
        "    op = sess.run(prediction, feed_dict={x:test_data[10]})\n",
        "    print (np.argmax(op))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}